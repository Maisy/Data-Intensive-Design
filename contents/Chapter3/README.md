# 3. 저장소와 검색

데이터베이스가 데이터를 저장하는방법

데이터를 요청했을때 다시 찾을수 있는 방법

→ 특정 workload 유형에서 저장소엔진이 어떻게 수행되는지 알아야 잘 선택할수있다.

(트랜젝션에 최적화된 엔진 vs 분석을 위해 최적화된 엔진:칼럼지향저장소...)

# 데이터베이스를 강력하게 만드는 데이터구조

**로그 구조화 색인(log-structured)**

- log: 연속된 추가 전용 레코드 라는 뜻
- 파일에 추가와 오래된 파일의 삭제만 허용하고 한 번 쓰여진 파일은 갱신하지 않는다.
- 수 Mbyte 이상의 가변크기의 세그먼트로 나누고 순차적으로 기록.
- 종류: 해시색인, SS table, ...

**페이지 지향 색인(page-oriented)**

- 고정크기의 블록이나 페이지로 나눠
- 종류: B트리

### 해시색인

- `키-바이트오프셋` 을 저장.
- hash map, hash table로 구성
- 키-값을 추가로 계속 저장한다. 순차쓰기라서 초빠름. 기존 데이터는 불변. (값을 덮어쓸때 데이터베이스가 죽는경우에 대해 걱정 ㄴㄴ)
- e.g.) 리악의 기본 저장소 엔진인 비트캐스크(Bitcask)에서 사용하는 방법.
- RAM에 모든 키가 저장된다는 조건하에 고성능 읽/쓰 가능. 키가 많지 않지만 갱신이 자주 일어나는 상황에 적합하다.

**키가 계속 늘어나면?**

→ 특정크기의 세그먼트로 로그를 나눈 뒤 압축(compaction)한다. (압축을 한다 = 각 키의 최신 값만 유지함)

    여러 세그먼트를 병합하면서 압축하기도 한다. (병합 시 순서가 중요하므로 항상 인접한 세그먼트끼리 병합해)

'동물:호출된횟수'를 저장한다고 했을때
 고양이1, 강아지8, 사자 2, 고양이2, 사자3, 고양이3, 고양이4 이런식으로 (세그먼트 크기만큼) 쭉 저장을 한 뒤 
'고양이4, 사자3, 강아지9' 로 압축을 한다. 

**제한사항**

- 키가 너무 많으면 문제. 무작위접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용 비쌈. 해시 충돌해소를 위한 로직 필요.
- range query에 비효율적이다.

### SS 테이블(Sorted String Table)과 LSM(Log Structured Merge) 트리

- 키-값 쌍을 키로 **정렬**. 각 키는 세그먼트 파일 내에 한번만 나타나야해.
- 정렬되어있으니까 특정 키값을 찾으려고 할때 처음부터 끝까지 다 안봐도된다.

**어떻게 정렬을 유지할까?**

→ 인메모리 balanced tree 데이터 구조 사용. (레드 블랙 트리, AVL 트리). 

- 이걸 memtable이라고 함.
- 임의 순서로 키를 삽입하고 정렬된 순서로 키를 다시 읽을 수 있다.
- 멤테이블이 특정 임곗값보다 커지면(보통 수 Mbyte) SS table 파일로 디스크에 기록함.
- 읽기 요청 시 멤테이블에서 찾고 > (디스크읽기시작) 가장 최신 세그먼트에서 찾고 > 두번째 최신 세그먼트에서 찾고...

**SS Table → LSM 트리 만들기**

- 백그라운드에서 연쇄적으로 SST를 병합
- 블룸필터(Bloom filter): 키가 데이터베이스에 없다는 걸 알려줘. 없는 데이터를 찾을때 모든 세그먼트를 뒤져야하는 문제를 해결하기 위해 사용.
- **SS Table을 압축/병합 하는 방법**
    - 사이즈 계층(size-tiered): 상대적으로 좀더 새롭고 작은 SS Table을 상대적으로 오래됐고 큰 SS Table에 병합.(HBase, Cassandra에서 지원함)
    - [level compaction](https://meeeejin.gitbooks.io/rocksdb-wiki-kr/content/leveled-compaction.html): 키 범위를 더 작은 SS Table로 나누고 오래된 데이터는 개별 '레벨'로 이동. (LevelDB, RocksDB, Cassandra에서 지원함)

LSM 트리

- 가능한 메모리 < 데이터셋 이어도 효과적이다.
- 정렬되어 있어서 range query 효율적이다.

### 제자리 갱신: B트리

- 세그먼트의 크기가 가변적이지 않고 보통 4KB(또는 그이상)의 **블록**이나 **페이지**로 나눔.
- 가장 널리 사용됨
- 각 페이지는 주소나 위치로 식별가능, 하나의 페이지가 다른 페이지를 참조할 수 있다.
- 분기계수(branching factor): 한 페이지에서 하위 페이지를 참조하는 수

    ![./btree.png](./btree.png)

    최상위에 있는 페이지의 분기계수는 3

- **균형**트리를 유지함. (n개의 키를 저장할때 깊이는 항상 O(log n))

**신뢰할 수 있는 B트리 만들기**

- 데이터를 덮어쓰기 때문에 일부 페이지만 기록하고 DB가 고장나면 색인이 훼손된다.
- 디스크에 쓰기 전 로그(write-ahead log, WAL, = 재실행로그 redo log)구조를 추가해 구현한다.
트리 페이지에 변경된 내용을 적용하기 전에 모든 변경사항을 기록하는 추가 전용 파일. (복구 때 사용)
- 동시성 제어는 래치(latch, 가벼운 lock)로 트리의 데이터 구조를 보호함.

**최적화**

- WAL대신 copy-on-write schema 사용: 변경된 페이지는 다른 위치에 기록하고 상위 트리에 새로운 버전을 만들어 새로운 위치를 가르키게 함. (이렇게 하면 동시성 제어도 편하다)
- 페이지에 전체 키를 저장하지 말고 축약해서 사용.(범위 경계만 표현 할 수 있으면 돼)
- 트리에 포인터를 추가함. 양쪽 형제 페이지에 대한 참조를 가지면 상위페이지로 다시 이동하지 않아도 키를 순서대로 스캔 할 수 있다.
- 리프페이지를 디스크 상에 연속된 순서로 나타나게 배치하면 모든 페이지를 다 찾아보지 않아도 된다. (그치만 트리가 커지면 순서 유지를 하기 어렵다.)
    - LSM트리는 병합할 때 다시 쓰기 때문에 연속된 키를 가깝게 유지하기 쉽다
- 프렉탈 트리(fractal tree): B Tree의 변형. 디스크 찾기를 줄이기 위해 로그 구조화 개념을 적용함.

**B tree vs LSM**

- LSM: 쓰기가 빠름.(순차적으로 쓰니까) 압축률이 더 좋음. compaction과정 시 읽/쓰할때 성능에 영향을 준다.
다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다.
- B Tree: 읽기가 빠름. 각 키가 색인의 한곳에만 정확하게 존재한다. 모든 데이터 조각을 최소한 두 번 기록해야한다.(WAL까지하니까)

### 그외 색인 구조

**Secondary index(보조 색인)**

- 조인을 효율적으로 수행할 때 역할을 함. Primary key색인과 다르게 키가 고유하지 않다.
- index의 각 값에 일치하는 row 식별자 목록을 만들거나 / 키에 row 식별자를 추가해 각 키를 고유하게 만든다.

**Clustered index(클러스터드 색인)**

- index안에 모든 row 데이터를 저장.
- 비클러스터드색인: index안에 row를 가르키는 참조만 저장. (heap file: 실제 row가 저장된 곳)
- covering index(커버링 색인), index with included column(포괄열이 있는 색인): 색인 안에 테이블의 칼럼 일부를 저장함. (색인만 사용해 일부 질의에 응답 가능)

**Multi-column index**

- 결합 색인(concatenated index): 하나의 키에 여러 필드를 단순히 결합
- e.g.) 지도에서 위도a~b + 경도 c~d까지 네모공간을 query할때

**Fuzzy 검색 기술**

- 유사하거나 애매모호한(fuzzy) 질의에 대한 응답
- 루씬에서는 질의의 오타에 대처하기 위해 특정 edit distance 이내에 있는 단어를 검색할 수 있게 함.
- edit distance: 한 글자가 추가되거나 삭제되거나 교체됐음을 의미함.

**In-memory DB**

- 주기적으로 스냅숏을 디스크에 저장하더라도 읽기는 메모리에서 사용하므로 인메모리 DB라고 할 수 있다.
- 관계형 모델 인메모리 DB: 볼트DB(VoltDB), 멤SQL(MemSQL), Oracle TimesTem
- RAMCloud: 지속성있는 오픈소스 인메모리 키-값 저장소. 메모리 데이터 + 디스크 데이터 모두 LSM 방식 사용.
- Redis, Couchbase: 비동기로 디스크에 기록하기 때문에 약한 residance
- In-memory db가 '디스크에서 읽지않아도 된다' 때문보다는 디스크에 기록하기 위한 형태로 부호화하는 오버헤드를 피할 수 있어서 더 빠를 수 있다.
- 안티캐싱(anti-caching): 메모리가 충분하지 않을 때 가장 최근에 사용하지 않은 데이터를 메모리에서 디스크로 내보내고 나중에 다시 접근할 때 메모리에 적재함.

## 트랜잭션 처리나 분석

여기서 트랜잭션은 배치에 비해 지연되는 시간이 낮게 읽기와 쓰기를 가능하게 한다는 의미.

보통 데이터를 넣고, 읽는 걸 온라인 트랜잭션 처리(OLTP, online transaction processing)이라고 하고, 카운트나 합, 평균과 같이 aggregation하는 걸 온라인 분석처리(OLAP, online analytic processing)이라고 해.

**데이터 웨어하우징**

- OLTP에 영향을 주지 않고 데이터 분석을 하기 위해서 데이터웨어하우스(data warehouse)라는 개별 데이터베이스를 만들어서 분석을 하는거.
    - ETL(Extract-Transform-Load): (OLTP DB로 부터) 데이터를 분석하기 쉬운 스키마로 변환(transform)하고 깨끗하게 정리해서 저장하는 것.
- 장점: 분석 패턴에 맞게 최적화할 수 있다.

OLTP: 분석 시스템
데이터 웨어하우스: ETL과정으로 저장을 한 DB.
데이터 레이크: 제일 raw한 데이터를 담는 DB. 분석이 필요한 시점에 가져와서 변환해서 씀.

상용 데이터웨어하우스 [redshift](https://aws.amazon.com/ko/redshift/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc)

**데이터 웨어하우스가 OLTP DB와 어떤 차이가 있을까?**

- 관계형 모델 사용.
- SQL 질의를 생성하고 결과를 시각화하고 분석가가 데이터를 탐색할 수 있게 해주는 그래픽 데이터 분석 도구가 있다. (drill-down, slicing, dicing)
- 둘다 SQL을 쓰지만 데이터웨어하우스는 분석 질의에 최적화되어 있다.

| Name           | OLTP                                      | OLAP                                  |
| -------------- | ----------------------------------------- | ------------------------------------- |
| 주요 읽기 패턴 | "질의당 적은 수의 레코드                  | 키 기준으로 가져옴"                   | 많은 레코드에 대한 집계 |
| 주요 쓰기 패턴 | "임의 접근                                | 사용자 입력을 낮은 지연시간으로 기록" | "bulk import(ETL)       | 또는 이벤트 스트림" |
| 주요 사용처    | 웹 애플리케이션을 통한 최종 사용자/소비자 | 의사결정 지원을 위한 내부 분석가      |
| 데이터 표현    | 데이터의 최신 상태(현재 시점)             | 시간이 지나며 일어난 이벤트 이력      |
| 데이터셋 크기  | GB~TB                                     | TB~PB                                 |
| 병목구간       | 디스크 탐색                               | 디스크 대역폭                         |

그럼 데이터 웨어하우스는 어떻게 모델링을 할까?

**분석용 스키마: 별 모양 스키마(star schema)와 눈꽃송이 모양 스키마**

- star schema = dimensional modeling (차원 모델링)
- **fact table(사실 테이블)**에 이벤트별로 데이터를 저장.(1 row = 1 event 발생). 로그를 쌓는 느낌으로?
- 정규화 테이블인데 fact table이 FK로 구성되어있다~
- 테이블이 매우 커질 수 있다.
- fact table의 일부 칼럼은 dimension table(차원 테이블)을 가르킨다. (외래키 참조)

    e.g.) fact_sale: date / product_id / price 가 칼럼이라고 했을 때
    dimension table은 product_id / product_name / category 칼럼으로 구성되어있는 product table이다.

- 더 변형된게 눈꽃송이 모양 스키마(snowflake schema)

[컬럼 지향 저장소](./column-oriented.md)

[3장 질문](./questions.md)